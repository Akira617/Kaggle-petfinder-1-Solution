{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1af16143",
   "metadata": {
    "papermill": {
     "duration": 0.015671,
     "end_time": "2022-01-09T17:53:46.266974",
     "exception": false,
     "start_time": "2022-01-09T17:53:46.251303",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "815b50b3",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-01-09T17:53:46.300758Z",
     "iopub.status.busy": "2022-01-09T17:53:46.299252Z",
     "iopub.status.idle": "2022-01-09T17:53:54.921582Z",
     "shell.execute_reply": "2022-01-09T17:53:54.922083Z",
     "shell.execute_reply.started": "2022-01-06T09:23:35.785368Z"
    },
    "papermill": {
     "duration": 8.640381,
     "end_time": "2022-01-09T17:53:54.922390",
     "exception": false,
     "start_time": "2022-01-09T17:53:46.282009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# based on the post here: https://www.kaggle.com/c/petfinder-pawpularity-score/discussion/275094\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../input/tez-lib/\")\n",
    "sys.path.append(\"../input/timmmaster/\")\n",
    "\n",
    "import tez\n",
    "import albumentations\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "from tez.callbacks import EarlyStopping\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import albumentations as A\n",
    "from PIL import Image\n",
    "\n",
    "class args:\n",
    "    batch_size = 16\n",
    "    image_size = 384\n",
    "    \n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "class Config:\n",
    "    data_dir = \"../input/petfinder-pawpularity-score/\"\n",
    "    output_dir = \".\"\n",
    "    img_train_dir = os.path.join(data_dir, \"train\")\n",
    "    img_test_dir = os.path.join(data_dir, \"test\")\n",
    "    random_seed = 42\n",
    "    tta_times = 4 # 1: no TTA ####\n",
    "    tta_beta = 1 / tta_times\n",
    "    model_path = \"swin_large_patch4_window7_224\"\n",
    "    pretrained = False\n",
    "    inp_channels = 3\n",
    "    im_size =  224\n",
    "    batch_size = 32\n",
    "    num_workers = 0 # >0: OS Error\n",
    "    out_features = 1\n",
    "    dropout = 0\n",
    "    \n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d29008",
   "metadata": {
    "papermill": {
     "duration": 0.013564,
     "end_time": "2022-01-09T17:53:54.949633",
     "exception": false,
     "start_time": "2022-01-09T17:53:54.936069",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define Swim Model and Swim Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f600ed15",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-01-09T17:53:55.002040Z",
     "iopub.status.busy": "2022-01-09T17:53:55.001125Z",
     "iopub.status.idle": "2022-01-09T17:53:55.003280Z",
     "shell.execute_reply": "2022-01-09T17:53:55.003659Z",
     "shell.execute_reply.started": "2022-01-06T09:23:44.09528Z"
    },
    "papermill": {
     "duration": 0.040494,
     "end_time": "2022-01-09T17:53:55.003786",
     "exception": false,
     "start_time": "2022-01-09T17:53:54.963292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PawpularDataset:\n",
    "    def __init__(self, image_paths, dense_features, targets, augmentations):\n",
    "        self.image_paths = image_paths\n",
    "        self.dense_features = dense_features\n",
    "        self.targets = targets\n",
    "        self.augmentations = augmentations\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        image = cv2.imread(self.image_paths[item])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.augmentations is not None:\n",
    "            augmented = self.augmentations(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "            \n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "        \n",
    "        features = self.dense_features[item, :]\n",
    "        targets = self.targets[item]\n",
    "        \n",
    "        return {\n",
    "            \"image\": torch.tensor(image, dtype=torch.float),\n",
    "            \"features\": torch.tensor(features, dtype=torch.float),\n",
    "            \"targets\": torch.tensor(targets, dtype=torch.float),\n",
    "        }\n",
    "    \n",
    "test_aug = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.Resize(args.image_size, args.image_size, p=1),\n",
    "        albumentations.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "            max_pixel_value=255.0,\n",
    "            p=1.0,\n",
    "        ),\n",
    "    ],\n",
    "    p=1.0,\n",
    ")\n",
    "    \n",
    "    \n",
    "class PetDataset(Dataset):\n",
    "    def __init__(self, image_filepaths, targets, transform=None):\n",
    "        self.image_filepaths = image_filepaths\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.image_filepaths[idx]\n",
    "        with open(image_filepath, 'rb') as f:\n",
    "            image = Image.open(f)\n",
    "            image_rgb = image.convert('RGB')\n",
    "        image = np.array(image_rgb)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image = image)[\"image\"]\n",
    "        \n",
    "        image = image / 255 # convert to 0-1\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        image = torch.tensor(image, dtype = torch.float)\n",
    "        target = torch.tensor(target, dtype = torch.float)\n",
    "        return image, target\n",
    "    \n",
    "    \n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]  # RGB\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]  # RGB\n",
    "def get_train_transforms(epoch, dim = Config.im_size):\n",
    "    return A.Compose(\n",
    "        [             \n",
    "            # resize like Resize in fastai\n",
    "            A.SmallestMaxSize(max_size=dim, p=1.0),\n",
    "            A.RandomCrop(height=dim, width=dim, p=1.0),\n",
    "            A.VerticalFlip(p = 0.5),\n",
    "            A.HorizontalFlip(p = 0.5)\n",
    "            #A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "        ]\n",
    "  )\n",
    "\n",
    "def get_inference_fixed_transforms(mode=0, dim = Config.im_size):\n",
    "    if mode == 0: # do not original aspects, colors and angles\n",
    "        return A.Compose([\n",
    "                A.SmallestMaxSize(max_size=dim, p=1.0),\n",
    "                A.CenterCrop(height=dim, width=dim, p=1.0),\n",
    "                #A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "            ], p=1.0)\n",
    "    elif mode == 1:\n",
    "        return A.Compose([\n",
    "                A.SmallestMaxSize(max_size=dim, p=1.0),\n",
    "                A.CenterCrop(height=dim, width=dim, p=1.0),\n",
    "                #A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),,\n",
    "                A.VerticalFlip(p = 1.0)\n",
    "            ], p=1.0)    \n",
    "    elif mode == 2:\n",
    "        return A.Compose([\n",
    "                A.SmallestMaxSize(max_size=dim, p=1.0),\n",
    "                A.CenterCrop(height=dim, width=dim, p=1.0),\n",
    "                #A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "                A.HorizontalFlip(p = 1.0)\n",
    "            ], p=1.0)\n",
    "    elif mode == 3:\n",
    "        return A.Compose([\n",
    "                A.SmallestMaxSize(max_size=dim, p=1.0),\n",
    "                A.CenterCrop(height=dim, width=dim, p=1.0),\n",
    "                #A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "                A.Transpose(p=1.0)\n",
    "            ], p=1.0)\n",
    "        \n",
    "def get_inference_random_transforms(mode=0, dim = Config.im_size):\n",
    "    if mode == 0: # do not original aspects, colors and angles\n",
    "        return A.Compose([\n",
    "                A.SmallestMaxSize(max_size=dim, p=1.0),\n",
    "                A.CenterCrop(height=dim, width=dim, p=1.0),\n",
    "                #A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "            ], p=1.0)\n",
    "    else:\n",
    "        return A.Compose(\n",
    "            [            \n",
    "                A.SmallestMaxSize(max_size=dim, p=1.0),\n",
    "                A.CenterCrop(height=dim, width=dim, p=1.0),\n",
    "                A.VerticalFlip(p = 0.5),\n",
    "                A.HorizontalFlip(p = 0.5)\n",
    "                #A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "            ]\n",
    "      ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b1cc0bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T17:53:55.043292Z",
     "iopub.status.busy": "2022-01-09T17:53:55.033314Z",
     "iopub.status.idle": "2022-01-09T17:53:55.045559Z",
     "shell.execute_reply": "2022-01-09T17:53:55.045129Z",
     "shell.execute_reply.started": "2022-01-06T09:23:44.126246Z"
    },
    "papermill": {
     "duration": 0.028131,
     "end_time": "2022-01-09T17:53:55.045666",
     "exception": false,
     "start_time": "2022-01-09T17:53:55.017535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PawpularModel(tez.Model):\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=False, in_chans=3)\n",
    "        self.model.head = nn.Linear(self.model.head.in_features, 128)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.dense1 = nn.Linear(140, 64)\n",
    "        self.dense2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, image, features, targets=None):\n",
    "        x1 = self.model(image)\n",
    "        x = self.dropout(x1)\n",
    "        x = torch.cat([x, features], dim=1)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        x = torch.cat([x, x1, features], dim=1)\n",
    "        return x, 0, {}\n",
    "    \n",
    "    \n",
    "class PetNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name = Config.model_path,\n",
    "        out_features = Config.out_features,\n",
    "        inp_channels=Config.inp_channels,\n",
    "        pretrained=Config.pretrained\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=inp_channels, num_classes = out_features)\n",
    "        print(\"self.model.head.in_features:\",self.model.head.in_features)\n",
    "        self.model.head = nn.Linear(self.model.head.in_features, 128) # 1536\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dense1 = nn.Linear(128, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(64, 1)\n",
    "\n",
    "    \n",
    "    def forward(self, image):\n",
    "        x1 = self.model(image)          # [bs, 128]\n",
    "        x = self.dropout1(x1)           # [bs, 128]\n",
    "        x = self.dense1(x)              # [bs, 64]\n",
    "        x = self.relu(x)                # [bs, 64]\n",
    "        x = self.dense2(x)              # [bs, 1]\n",
    "        x2 = torch.cat([x, x1], dim=1)  # [bs, 129]\n",
    "        return x, x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7419d822",
   "metadata": {
    "papermill": {
     "duration": 0.013378,
     "end_time": "2022-01-09T17:53:55.072327",
     "exception": false,
     "start_time": "2022-01-09T17:53:55.058949",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import RAPIDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166c852a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T17:53:55.104410Z",
     "iopub.status.busy": "2022-01-09T17:53:55.103765Z",
     "iopub.status.idle": "2022-01-09T17:53:58.593549Z",
     "shell.execute_reply": "2022-01-09T17:53:58.594304Z",
     "shell.execute_reply.started": "2022-01-06T09:23:44.142925Z"
    },
    "papermill": {
     "duration": 3.507619,
     "end_time": "2022-01-09T17:53:58.594498",
     "exception": false,
     "start_time": "2022-01-09T17:53:55.086879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cuml, pickle\n",
    "from cuml.svm import SVR\n",
    "print('RAPIDS version',cuml.__version__,'\\n')\n",
    "\n",
    "LOAD_SVR_FROM_PATH = None\n",
    "\n",
    "df = pd.read_csv('../input/petfindermodel/train_df_010524.csv') \n",
    "# '../input/petfindermodel2/train_df_10fold_010617.csv'\n",
    "\n",
    "print('Train shape:', df.shape )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "097608e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T17:53:58.628682Z",
     "iopub.status.busy": "2022-01-09T17:53:58.627945Z",
     "iopub.status.idle": "2022-01-09T17:53:58.630320Z",
     "shell.execute_reply": "2022-01-09T17:53:58.629807Z",
     "shell.execute_reply.started": "2022-01-07T04:56:22.657589Z"
    },
    "papermill": {
     "duration": 0.020357,
     "end_time": "2022-01-09T17:53:58.630431",
     "exception": false,
     "start_time": "2022-01-09T17:53:58.610074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "####\n",
    "model_weight = [\n",
    "                '../input/petfindermodel4/010816_swin_large_patch4_window7_224_fold0_cv17702.pth',\n",
    "                '../input/petfindermodel4/010816_swin_large_patch4_window7_224_fold1_cv17327.pth',\n",
    "                '../input/petfindermodel4/010816_swin_large_patch4_window7_224_fold2_cv17635.pth',\n",
    "                '../input/petfindermodel4/010816_swin_large_patch4_window7_224_fold3_cv17401.pth',\n",
    "                '../input/petfindermodel4/010816_swin_large_patch4_window7_224_fold4_cv17302.pth',\n",
    "]\n",
    "\n",
    "# model_fold_idx_list = [2,3,4,5,7,8,12,13,16,17]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a723bc",
   "metadata": {
    "papermill": {
     "duration": 0.013866,
     "end_time": "2022-01-09T17:53:58.760681",
     "exception": false,
     "start_time": "2022-01-09T17:53:58.746815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Infer Test and OOF\n",
    "In version 1 of this notebook, we extract train embeddings and train RAPIDS SVR heads. (Click version 1 to see this). In later versions and during Kaggle submit, we load these saved RAPIDS SVR fold models and just infer data (without training anything)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee68d529",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T17:53:58.819120Z",
     "iopub.status.busy": "2022-01-09T17:53:58.818303Z",
     "iopub.status.idle": "2022-01-09T18:18:13.825754Z",
     "shell.execute_reply": "2022-01-09T18:18:13.826154Z",
     "shell.execute_reply.started": "2022-01-06T09:23:47.687742Z"
    },
    "papermill": {
     "duration": 1455.051379,
     "end_time": "2022-01-09T18:18:13.826327",
     "exception": false,
     "start_time": "2022-01-09T17:53:58.774948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "super_final_predictions = []\n",
    "super_final_predictions2 = []\n",
    "super_final_oof_predictions = []\n",
    "super_final_oof_predictions2 = []\n",
    "super_final_oof_true = []\n",
    "\n",
    "for fold_ in range(5):\n",
    "    print('#'*25)\n",
    "    print('### FOLD',fold_)\n",
    "    print('#'*25)\n",
    "    \n",
    "    model = PetNet()\n",
    "    model.load_state_dict(torch.load(model_weight[fold_]))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    df_test = pd.read_csv(\"../input/petfinder-pawpularity-score/test.csv\")\n",
    "    test_img_paths = [f\"../input/petfinder-pawpularity-score/test/{x}.jpg\" for x in df_test[\"Id\"].values]\n",
    "        \n",
    "    df_valid = df[df.fold == fold_].reset_index(drop=True)#.iloc[:160]\n",
    "    valid_img_paths = [f\"../input/petfinder-pawpularity-score/train/{x}.jpg\" for x in df_valid[\"Id\"].values]\n",
    "\n",
    "    dense_features = [\n",
    "        'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n",
    "        'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'\n",
    "    ]\n",
    "    \n",
    "    name = f\"SVR_fold_{fold_}.pkl\" \n",
    "    if LOAD_SVR_FROM_PATH is None:\n",
    "        # EXTRACT TRAIN EMBEDDINGS\n",
    "        \n",
    "        df_train = df[df.fold != fold_].reset_index(drop=True)#.iloc[:320]\n",
    "        train_img_paths = [f\"../input/petfinder-pawpularity-score/train/{x}.jpg\" for x in df_train[\"Id\"].values]\n",
    "        \n",
    "        train_dataset = PetDataset(\n",
    "          image_filepaths = train_img_paths,\n",
    "          targets = df_train['Pawpularity'].values/100,\n",
    "          transform = get_inference_fixed_transforms(0)\n",
    "        )\n",
    "    \n",
    "        train_loader = DataLoader(train_dataset, batch_size=Config.batch_size, shuffle=False, num_workers=Config.num_workers, pin_memory = True)\n",
    "        \n",
    "        print('Extracting train embedding...')\n",
    "        fold_preds = []\n",
    "        for i, (images, target) in enumerate(tqdm(train_loader), start = 1):\n",
    "            images = images.to(device, non_blocking = True).float()\n",
    "            target = target.to(device, non_blocking = True).float().view(-1, 1)\n",
    "            with torch.no_grad():\n",
    "                _, output = model(images)\n",
    "            fold_preds.append(output.detach().cpu().numpy())\n",
    "        \n",
    "        embed = np.array([]).reshape((0,128))\n",
    "        for preds in fold_preds:\n",
    "            embed = np.concatenate([embed,preds[:,1:]],axis=0)\n",
    "        \n",
    "        # FIT RAPIDS SVR\n",
    "        print('Fitting SVR...')\n",
    "        clf = SVR(C=20.0)\n",
    "        clf.fit(embed.astype('float32'), df_train.Pawpularity.values.astype('int32'))\n",
    "    \n",
    "        # SAVE RAPIDS SVR \n",
    "        pickle.dump(clf, open(name, \"wb\"))\n",
    "        \n",
    "    else:\n",
    "        # LOAD RAPIDS SVR \n",
    "        print('Loading SVR...',LOAD_SVR_FROM_PATH+name)\n",
    "        clf = pickle.load(open(LOAD_SVR_FROM_PATH+name, \"rb\"))\n",
    "\n",
    "        \n",
    "    # ************ TEST PREDICTIONS ************\n",
    "    test_dataset = PetDataset(\n",
    "          image_filepaths = test_img_paths,\n",
    "          targets = np.zeros(len(test_img_paths)),\n",
    "          transform = get_inference_fixed_transforms(0)\n",
    "        )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=Config.batch_size, shuffle=False, num_workers=Config.num_workers, pin_memory = True)\n",
    "    print('Predicting test...')\n",
    "    \n",
    "    \n",
    "    fold_preds = []\n",
    "    for i, (images, target) in enumerate(tqdm(test_loader), start = 1):\n",
    "        images = images.to(device, non_blocking = True).float()\n",
    "        target = target.to(device, non_blocking = True).float().view(-1, 1)\n",
    "        with torch.no_grad():\n",
    "            _, output = model(images)\n",
    "        fold_preds.append(output.detach().cpu().numpy())\n",
    "    \n",
    "\n",
    "    final_test_predictions = []\n",
    "    embed = np.array([]).reshape((0,128))\n",
    "    for preds in fold_preds: #tqdm\n",
    "        final_test_predictions.extend(preds[:,:1].ravel().tolist())\n",
    "        embed = np.concatenate([embed,preds[:,1:]],axis=0)\n",
    "\n",
    "    final_test_predictions = [sigmoid(x) * 100 for x in final_test_predictions]\n",
    "    final_test_predictions2 = clf.predict(embed)\n",
    "    super_final_predictions.append(final_test_predictions)\n",
    "    super_final_predictions2.append(final_test_predictions2)\n",
    "    \n",
    "    \n",
    "    # ************ OOF PREDICTIONS ************ \n",
    "    valid_dataset = PetDataset(\n",
    "          image_filepaths = valid_img_paths,\n",
    "          targets = df_valid['Pawpularity'].values/100,\n",
    "          transform = get_inference_fixed_transforms(0)\n",
    "        )\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=Config.batch_size, shuffle=False, num_workers=Config.num_workers, pin_memory = True)\n",
    "    \n",
    "    print('Predicting oof...')\n",
    "    fold_preds = []\n",
    "    for i, (images, target) in enumerate(tqdm(valid_loader), start = 1):\n",
    "        images = images.to(device, non_blocking = True).float()\n",
    "        target = target.to(device, non_blocking = True).float().view(-1, 1)\n",
    "        with torch.no_grad():\n",
    "            _, output = model(images)\n",
    "        fold_preds.append(output.detach().cpu().numpy())\n",
    "    \n",
    "\n",
    "    final_oof_predictions = []\n",
    "    embed = np.array([]).reshape((0,128))\n",
    "    for preds in fold_preds:\n",
    "        final_oof_predictions.extend(preds[:,:1].ravel().tolist())\n",
    "        embed = np.concatenate([embed,preds[:,1:]],axis=0)\n",
    "\n",
    "    final_oof_predictions = [sigmoid(x) * 100 for x in final_oof_predictions]\n",
    "    final_oof_predictions2 = clf.predict(embed)    \n",
    "    super_final_oof_predictions.append(final_oof_predictions)\n",
    "    super_final_oof_predictions2.append(final_oof_predictions2)\n",
    "    \n",
    "    final_oof_true = df_valid['Pawpularity'].values\n",
    "    super_final_oof_true.append(final_oof_true)\n",
    "    \n",
    "    # COMPUTE RSME\n",
    "    rsme = np.sqrt( np.mean( (super_final_oof_true[-1] - np.array(super_final_oof_predictions[-1]))**2.0 ) )\n",
    "    print('NN RSME =',rsme,'\\n')\n",
    "    rsme = np.sqrt( np.mean( (super_final_oof_true[-1] - np.array(super_final_oof_predictions2[-1]))**2.0 ) )\n",
    "    print('SVR RSME =',rsme,'\\n')\n",
    "    \n",
    "    w = 0.2\n",
    "    oof2 = (1-w)*np.array(super_final_oof_predictions[-1]) + w*np.array(super_final_oof_predictions2[-1])\n",
    "    rsme = np.sqrt( np.mean( (super_final_oof_true[-1] - oof2)**2.0 ) )\n",
    "    print('Ensemble RSME =',rsme,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5240db1",
   "metadata": {
    "papermill": {
     "duration": 0.433395,
     "end_time": "2022-01-09T18:18:14.703898",
     "exception": false,
     "start_time": "2022-01-09T18:18:14.270503",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Compute CV Score\n",
    "Below we compute the overall CV RSME scores of just the NN head, just the SVR head, and an ensemble of 50% NN and 50% SVR heads. Then we plot all ensemble weights to find the optimal weights for NN head and SVR heads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e572664",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T18:18:15.582962Z",
     "iopub.status.busy": "2022-01-09T18:18:15.580066Z",
     "iopub.status.idle": "2022-01-09T18:18:15.588291Z",
     "shell.execute_reply": "2022-01-09T18:18:15.587836Z",
     "shell.execute_reply.started": "2022-01-06T09:48:04.029545Z"
    },
    "papermill": {
     "duration": 0.444946,
     "end_time": "2022-01-09T18:18:15.588408",
     "exception": false,
     "start_time": "2022-01-09T18:18:15.143462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "true = np.hstack(super_final_oof_true)\n",
    "\n",
    "oof = np.hstack(super_final_oof_predictions)\n",
    "rsme = np.sqrt( np.mean( (oof - true)**2.0 ))\n",
    "print('Overall CV NN head RSME =',rsme)\n",
    "\n",
    "oof2 = np.hstack(super_final_oof_predictions2)\n",
    "rsme = np.sqrt( np.mean( (oof2 - true)**2.0 ))\n",
    "print('Overall CV SVR head RSME =',rsme)\n",
    "\n",
    "oof3 = (1-w)*oof + w*oof2\n",
    "rsme = np.sqrt( np.mean( (oof3 - true)**2.0 ))\n",
    "print('Overall CV Ensemble heads RSME with 50% NN and 50% SVR =',rsme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77509195",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-01-09T18:18:16.474699Z",
     "iopub.status.busy": "2022-01-09T18:18:16.473980Z",
     "iopub.status.idle": "2022-01-09T18:18:16.686761Z",
     "shell.execute_reply": "2022-01-09T18:18:16.687139Z",
     "shell.execute_reply.started": "2022-01-06T09:48:04.044864Z"
    },
    "papermill": {
     "duration": 0.65259,
     "end_time": "2022-01-09T18:18:16.687312",
     "exception": false,
     "start_time": "2022-01-09T18:18:16.034722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "score = []\n",
    "for ww in np.arange(0,1.05,0.05):\n",
    "    oof3 = (1-ww)*oof + ww*oof2\n",
    "    rsme = np.sqrt( np.mean( (oof3 - true)**2.0 ))\n",
    "    #print(f'{ww:0.2} CV Ensemble RSME =',rsme)\n",
    "    score.append(rsme)\n",
    "best_w = np.argmin(score)*0.05\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(np.arange(21)/20.0,score,'-o')\n",
    "plt.plot([best_w],np.min(score),'o',color='black',markersize=15)\n",
    "plt.title(f'Best Overall CV RSME={np.min(score):.4} with SVR Ensemble Weight={best_w:.2}',size=16)\n",
    "plt.ylabel('Overall Ensemble RSME',size=14)\n",
    "plt.xlabel('SVR Weight',size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf16cc06",
   "metadata": {
    "papermill": {
     "duration": 0.426457,
     "end_time": "2022-01-09T18:18:17.590260",
     "exception": false,
     "start_time": "2022-01-09T18:18:17.163803",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Trust CV or LB?\n",
    "Above we see that using 50% NN head and 50% SVR head achieves the best overall CV score. However our RAPIDS SVR head isn't helping public LB much. We also notice that our RAPIDS SVR head helped folds `1, 2, 4, 5, 7, 8, 9, 10` but did not help folds `3, 6`. So is public test data just a \"bad fold\"? Will our RAPIDS SVR head help private LB? Below we force the weight of SVR head to be 10% in order to achieve a slight public LB boost. But maybe for final submission, we should use 50%??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e1539d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T18:18:18.456720Z",
     "iopub.status.busy": "2022-01-09T18:18:18.456120Z",
     "iopub.status.idle": "2022-01-09T18:18:18.460378Z",
     "shell.execute_reply": "2022-01-09T18:18:18.459950Z",
     "shell.execute_reply.started": "2022-01-06T09:48:04.381615Z"
    },
    "papermill": {
     "duration": 0.441818,
     "end_time": "2022-01-09T18:18:18.460494",
     "exception": false,
     "start_time": "2022-01-09T18:18:18.018676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FORCE SVR WEIGHT TO LOWER VALUE TO HELP PUBLIC LB\n",
    "# best_w = 0.2\n",
    "print(f\"best_w:{best_w}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6054c74",
   "metadata": {
    "papermill": {
     "duration": 0.438501,
     "end_time": "2022-01-09T18:18:19.328943",
     "exception": false,
     "start_time": "2022-01-09T18:18:18.890442",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Make Submission CSV\n",
    "We make a submission csv using an ensemble of both heads. We use the optimal ensemble weights that we discovered above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039e799b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-09T18:18:20.209802Z",
     "iopub.status.busy": "2022-01-09T18:18:20.209228Z",
     "iopub.status.idle": "2022-01-09T18:18:20.224445Z",
     "shell.execute_reply": "2022-01-09T18:18:20.224920Z",
     "shell.execute_reply.started": "2022-01-06T09:48:04.395008Z"
    },
    "papermill": {
     "duration": 0.461497,
     "end_time": "2022-01-09T18:18:20.225071",
     "exception": false,
     "start_time": "2022-01-09T18:18:19.763574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "super_final_predictions = np.mean(np.column_stack(super_final_predictions), axis=1)\n",
    "super_final_predictions2 = np.mean(np.column_stack(super_final_predictions2), axis=1)\n",
    "df_test[\"Pawpularity\"] = (1-best_w)*super_final_predictions + best_w*super_final_predictions2\n",
    "df_test = df_test[[\"Id\", \"Pawpularity\"]]\n",
    "df_test.to_csv(\"submission.csv\", index=False)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a82d669",
   "metadata": {
    "papermill": {
     "duration": 0.432764,
     "end_time": "2022-01-09T18:18:21.098641",
     "exception": false,
     "start_time": "2022-01-09T18:18:20.665877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1484.245751,
   "end_time": "2022-01-09T18:18:23.862089",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-09T17:53:39.616338",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
